{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGSBsVTzaE/Bs8Bwkhaq8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vika0408/Mental-Health/blob/main/helpingminds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brd_En9JHrC6",
        "outputId": "4d8b1283-462b-4e17-ceed-4ecc2c5de1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "! pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"zaber666/meld-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC-KhdXsIK5T",
        "outputId": "f5ada463-eaf2-4734-9afe-dbbc46582692"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming download from 509607936 bytes (11295054176 bytes left)...\n",
            "Resuming download from https://www.kaggle.com/api/v1/datasets/download/zaber666/meld-dataset?dataset_version_number=1 (509607936/11804662112) bytes left.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [02:02<00:00, 91.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zaber666/meld-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, LSTM, Dense, Dropout, Bidirectional, MultiHeadAttention,\n",
        "    LayerNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "zpGuMB5wLIGy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/root/.cache/kagglehub/datasets/zaber666/meld-dataset/versions/1\"\n"
      ],
      "metadata": {
        "id": "ri7wnIV6LXaD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/root/.cache/kagglehub/datasets/zaber666/meld-dataset/versions/1/MELD-RAW/MELD.Raw/train/train_sent_emo.csv')"
      ],
      "metadata": {
        "id": "m0XJ8XlHMMae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text preprocessing\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Utterance'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['Utterance'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n"
      ],
      "metadata": {
        "id": "f0BdFGIeNYxo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding\n",
        "label_encoder_sentiment = LabelEncoder()\n",
        "label_encoder_emotion = LabelEncoder()\n",
        "\n",
        "df['Sentiment'] = label_encoder_sentiment.fit_transform(df['Sentiment'])\n",
        "df['Emotion'] = label_encoder_emotion.fit_transform(df['Emotion'])\n",
        "\n",
        "sentiment_labels = np.array(df['Sentiment'])\n",
        "emotion_labels = np.array(df['Emotion'])"
      ],
      "metadata": {
        "id": "X2aAq505NdqX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data\n",
        "X_train, X_test, y_train_sentiment, y_test_sentiment, y_train_emotion, y_test_emotion = train_test_split(\n",
        "    padded_sequences, sentiment_labels, emotion_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Ensure proper NumPy format\n",
        "y_train_sentiment = np.array(y_train_sentiment, dtype=np.int32)\n",
        "y_test_sentiment = np.array(y_test_sentiment, dtype=np.int32)\n",
        "y_train_emotion = np.array(y_train_emotion, dtype=np.int32)\n",
        "y_test_emotion = np.array(y_test_emotion, dtype=np.int32)"
      ],
      "metadata": {
        "id": "YTCtAIg9NtPQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model define\n",
        "VOCAB_SIZE = MAX_VOCAB_SIZE\n",
        "EMBEDDING_DIM = 128\n",
        "LSTM_UNITS = 256  # Reduced from 512 to prevent overfitting\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "\n",
        "# Embedding layer with masking\n",
        "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)(inputs)\n",
        "\n",
        "# Bidirectional LSTM with dropout\n",
        "x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True, dropout=DROPOUT_RATE, recurrent_dropout=0.2, unroll=False, use_cudnn=False))(x)\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "\n",
        "# Multi-Head Self-Attention\n",
        "attention_output = MultiHeadAttention(num_heads=4, key_dim=LSTM_UNITS)(x, x)\n",
        "x = LayerNormalization()(x + attention_output)\n",
        "\n",
        "# Global Pooling\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "# Sentiment output\n",
        "sentiment_output = Dense(3, activation=\"softmax\", name=\"sentiment_output\")(x)\n",
        "\n",
        "# Emotion output\n",
        "emotion_output = Dense(7, activation=\"softmax\", name=\"emotion_output\")(x)\n",
        "\n",
        "# Build Model\n",
        "model = Model(inputs, outputs=[sentiment_output, emotion_output])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=0.0003, weight_decay=1e-5),\n",
        "    loss={\n",
        "        \"sentiment_output\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "        \"emotion_output\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    },\n",
        "    metrics={\n",
        "        \"sentiment_output\": [\"accuracy\"],\n",
        "        \"emotion_output\": [\"accuracy\"]\n",
        "    }\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "IWX4xLzXKYFS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "D4yxfYOYSwQD",
        "outputId": "cdc71c80-2587-44db-d179-13ebcdac8d36"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m788,480\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,100,736\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sentiment_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │          \u001b[38;5;34m1,539\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │          \u001b[38;5;34m3,591\u001b[0m │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100,736</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sentiment_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,175,370\u001b[0m (15.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,175,370</span> (15.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,175,370\u001b[0m (15.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,175,370</span> (15.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    {\"sentiment_output\": y_train_sentiment, \"emotion_output\": y_train_emotion},  # ✅ Corrected output names\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, {\"sentiment_output\": y_test_sentiment, \"emotion_output\": y_test_emotion}),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9NZMLX6S0nS",
        "outputId": "12884c34-eb22-41fe-94d7-9ffa04f6eded"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 805ms/step - emotion_output_accuracy: 0.4484 - emotion_output_loss: 1.5846 - loss: 2.6458 - sentiment_output_accuracy: 0.4579 - sentiment_output_loss: 1.0611 - val_emotion_output_accuracy: 0.5030 - val_emotion_output_loss: 1.4441 - val_loss: 2.4349 - val_sentiment_output_accuracy: 0.5345 - val_sentiment_output_loss: 1.0105\n",
            "Epoch 2/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 806ms/step - emotion_output_accuracy: 0.4907 - emotion_output_loss: 1.4023 - loss: 2.3632 - sentiment_output_accuracy: 0.5451 - sentiment_output_loss: 0.9609 - val_emotion_output_accuracy: 0.5135 - val_emotion_output_loss: 1.4351 - val_loss: 2.4097 - val_sentiment_output_accuracy: 0.5591 - val_sentiment_output_loss: 0.9919\n",
            "Epoch 3/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 803ms/step - emotion_output_accuracy: 0.5634 - emotion_output_loss: 1.2386 - loss: 2.0795 - sentiment_output_accuracy: 0.6213 - sentiment_output_loss: 0.8409 - val_emotion_output_accuracy: 0.5200 - val_emotion_output_loss: 1.4948 - val_loss: 2.5207 - val_sentiment_output_accuracy: 0.5581 - val_sentiment_output_loss: 1.0417\n",
            "Epoch 4/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 810ms/step - emotion_output_accuracy: 0.5947 - emotion_output_loss: 1.1148 - loss: 1.8546 - sentiment_output_accuracy: 0.6642 - sentiment_output_loss: 0.7398 - val_emotion_output_accuracy: 0.5045 - val_emotion_output_loss: 1.5484 - val_loss: 2.6140 - val_sentiment_output_accuracy: 0.5516 - val_sentiment_output_loss: 1.0775\n",
            "Epoch 5/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 808ms/step - emotion_output_accuracy: 0.6429 - emotion_output_loss: 1.0107 - loss: 1.6816 - sentiment_output_accuracy: 0.7116 - sentiment_output_loss: 0.6709 - val_emotion_output_accuracy: 0.4985 - val_emotion_output_loss: 1.6627 - val_loss: 2.7814 - val_sentiment_output_accuracy: 0.5410 - val_sentiment_output_loss: 1.1300\n",
            "Epoch 6/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 797ms/step - emotion_output_accuracy: 0.6805 - emotion_output_loss: 0.9269 - loss: 1.5434 - sentiment_output_accuracy: 0.7249 - sentiment_output_loss: 0.6165 - val_emotion_output_accuracy: 0.4855 - val_emotion_output_loss: 1.7303 - val_loss: 2.9056 - val_sentiment_output_accuracy: 0.5400 - val_sentiment_output_loss: 1.1791\n",
            "Epoch 7/30\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 796ms/step - emotion_output_accuracy: 0.7127 - emotion_output_loss: 0.8445 - loss: 1.4270 - sentiment_output_accuracy: 0.7553 - sentiment_output_loss: 0.5825 - val_emotion_output_accuracy: 0.4790 - val_emotion_output_loss: 1.9344 - val_loss: 3.2529 - val_sentiment_output_accuracy: 0.5195 - val_sentiment_output_loss: 1.3227\n"
          ]
        }
      ]
    }
  ]
}